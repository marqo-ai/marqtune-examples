{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dm44RZLWSBm9"
      },
      "source": [
        "# **Getting Started with Marqtune - A Guided Walkthrough**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6E6bjsFcSalc"
      },
      "source": [
        "This notebook contains information on how to get up and running with Marqtune, the embedding model training platform. We have an in-depth [article](https://marqo.ai/blog/getting-started-with-marqtune) to accompany this walkthrough which we highly recommend reading."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TI6Aa-ADSsau"
      },
      "source": [
        "This guide will walk you through the process of fine tuning a model based on a base open clip model using a multi-modal training dataset. We will then evaluate the performance of the tuned model and compare it with an equivalent evaluation of the base model to demonstrate an improvement in performance. This tuned model can subsequently be used in a [Marqo index](https://cloud.marqo.ai/) to provide more relevant results for queries."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9PHXEh3S1lx"
      },
      "source": [
        "Let's get stuck in!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v8A7HbZdVFnM"
      },
      "source": [
        "### **1. Set Up and Installation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "peEViJXfYd98"
      },
      "source": [
        "To use Marqtune you will need the Marqtune Python client. You can install this using pip:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tulkcLIAYZIv",
        "outputId": "4d4857b1-3c23-40af-f7c6-6192eeaa5d30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting marqtune\n",
            "  Downloading marqtune-0.2.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from marqtune) (2.32.3)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from marqtune) (2.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->marqtune) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->marqtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->marqtune) (2024.8.30)\n",
            "Downloading marqtune-0.2.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: marqtune\n",
            "Successfully installed marqtune-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install marqtune"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYOfmkwxYgjE"
      },
      "source": [
        "Next, you will need a Marqo API key with access to Marqtune. To obtain this, sign in to your Marqo Cloud and navigate to the API keys section and create your own. For more information on obtaining your Marqo API Key, see this [article](https://marqo.ai/blog/finding-my-marqo-api-key)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Onxy8N_XTTbp"
      },
      "source": [
        "We are using Google Colab so we will take advantage of 'Secrets' which allows you to store environment variables privately. Navigate to the 'key' logo on the lefthand side navigation bar and store your API key there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KpF4OkS0WaUN"
      },
      "outputs": [],
      "source": [
        "# Store Marqo API Key using Secrets in Google Colab\n",
        "from google.colab import userdata\n",
        "api_key = userdata.get('MARQO_API_KEY')   # alternatively, api_key = \"...\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_1P1iFeVMBq"
      },
      "source": [
        "### **2. Initializing the Client**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w51ksgRiTxoW"
      },
      "source": [
        "We now make the necessary imports and setup the Marqtune Python client."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EuCWtCSJaiPJ",
        "outputId": "cce4dee6-36eb-4643-acd0-760a9d0762de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using suffix=d166c36f for this walkthrough\n"
          ]
        }
      ],
      "source": [
        "from marqtune.client import Client\n",
        "from marqtune.enums import DatasetType, InstanceType\n",
        "from urllib.request import urlopen\n",
        "import gzip\n",
        "import json\n",
        "import uuid\n",
        "import os\n",
        "\n",
        "# Suffix is used just to make the dataset and model names unique\n",
        "suffix = str(uuid.uuid4())[:8]\n",
        "print(f\"Using suffix={suffix} for this walkthrough\")\n",
        "\n",
        "# Set up Marqtune Client\n",
        "# To find your API Key, go to Marqo Cloud and click 'API Keys' from the lefthand side navigation bar or visit https://www.marqo.ai/blog/finding-my-marqo-api-key\n",
        "marqtune_client = Client(url=\"https://marqtune.marqo.ai\", api_key=api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emjvdzwdUAnr"
      },
      "source": [
        "To see the results of datasets and other resources generated in this walkthrough in the Marqtune UI, please refer to our [article](https://marqo.ai/blog/getting-started-with-marqtune)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "59fAt0jMVQ7h"
      },
      "source": [
        "### **3. Dataset Creation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WamVMuZkUNS8"
      },
      "source": [
        "We will now create two datasets, one for training and another for evaluation. The datasets will be sourced from a couple of CSV files. The data in these CSV files consists of shopping data generated from a subset of `Marqo-GS-10M` which is described in more detail in our [open-source GCL repository](https://github.com/marqo-ai/GCL).\n",
        "\n",
        "Both CSV files have the same format; however, the first one is larger (100,000 rows) which we will use for training a model, the second is smaller (25,000 rows) which we will use for model evaluation.\n",
        "\n",
        "The datasets are multi-modal, consisting of both text and images. The images are represented by URLs that Marqtune will use to download.\n",
        "\n",
        "Let’s begin by downloading these data files:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPwOAXRfXfZh",
        "outputId": "4c712d10-7e1e-432c-ea6c-af4939a17a8a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data files:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "5079946"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(\"Downloading data files:\")\n",
        "base_path = (\n",
        "    \"https://marqo-gcl-public.s3.us-west-2.amazonaws.com/marqtune_test/datasets/v1\"\n",
        ")\n",
        "training_data = \"gs_100k_training.csv\"\n",
        "eval_data = \"gs_25k_eval.csv\"\n",
        "open(training_data, \"w\").write(\n",
        "    gzip.open(urlopen(f\"{base_path}/{training_data}.gz\"), \"rb\").read().decode(\"utf-8\")\n",
        ")\n",
        "open(eval_data, \"w\").write(\n",
        "    gzip.open(urlopen(f\"{base_path}/{eval_data}.gz\"), \"rb\").read().decode(\"utf-8\")\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyHM1Wg7USqf"
      },
      "source": [
        "We now want to create datasets in Marqtune. In order to do this, we need to identify the columns in the CSVs as well as their types by defining a data schema. We will reuse the same data schema for both training and evaluation datasets though this is not strictly necessary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "id": "m5NUJxoEaxae"
      },
      "outputs": [],
      "source": [
        "data_schema = {\n",
        "    \"query\": \"text\",\n",
        "    \"title\": \"text\",\n",
        "    \"image\": \"image_pointer\",\n",
        "    \"score\": \"score\",\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZThOaQKDUTRq"
      },
      "source": [
        "After defining the data schema we can then create the two datasets. Note that creating a dataset takes a few minutes to complete as it accomplishes a few steps:\n",
        "\n",
        "1. The CSV file has to be uploaded\n",
        "2. Some simple validations have to pass (e.g. the data schema needs to be validated against each row in the CSV input)\n",
        "3. The URLs in the `image_pointer` columns are used to download the image files to the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "06y8vNWVwBrm",
        "outputId": "e263b295-4a63-4d7e-a643-183777f1ba2c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating training dataset (gs_100k_training.csv-d166c36f):\n",
            "Dataset was initialised. Dataset ID: 426c58ac-0732-44dc-ac10-d734ffaada38\n",
            "Attempting to upload file...\n",
            "File uploaded successfully. Job will start soon\n",
            "Uploading..\n",
            "Creating: Provisioning...\n",
            "Creating: Running\n",
            "2024-10-01 15:09:12,619 - INFO - Initialising task\n",
            "2024-10-01 15:09:12,688 - INFO - Downloading files for task 426c58ac-0732-44dc-ac10-d734ffaada38\n",
            "2024-10-01 15:09:13,247 - INFO - File download is completed\n",
            "2024-10-01 15:09:13,249 - INFO - Preparing dataset with {'input_file': 'dataset/426c58ac-0732-44dc-ac10-d734ffaada38/dataset.csv', 'data_schema': {'query': 'text', 'title': 'text', 'image': 'image_pointer', 'score': 'score'}, 'output_path': '426c58ac-0732-44dc-ac10-d734ffaada38', 'dataset_type': 'training', 'result_columns': None, 'image_download_headers': None, 'logger': <Logger __main__ (DEBUG)>, 'metrics_collector': <clients.cw_client.CWClient object at 0xffffa151cb90>}\n",
            "2024-10-01 15:09:13,518 - INFO - Total rows after cleaning up dataset: 100000, rows dropped: 0\n",
            "2024-10-01 15:09:13,520 - INFO - Initiating file processing. It will validate every row and download images. Please wait, this process may take a while.\n",
            "2024-10-01 15:09:13,539 - INFO - Image download started for 96243 images.\n",
            "2024-10-01 15:09:16,157 - INFO - Downloaded 1924/96243(2.0%) images - Elapsed time: 00:00:02, Estimated total time: 00:02:10, Estimated time left: 00:02:08\n",
            "2024-10-01 15:09:18,276 - INFO - Downloaded 3848/96243(4.0%) images - Elapsed time: 00:00:04, Estimated total time: 00:01:58, Estimated time left: 00:01:53\n",
            "2024-10-01 15:09:20,385 - INFO - Downloaded 5772/96243(6.0%) images - Elapsed time: 00:00:06, Estimated total time: 00:01:54, Estimated time left: 00:01:47\n",
            "2024-10-01 15:09:22,484 - INFO - Downloaded 7696/96243(8.0%) images - Elapsed time: 00:00:08, Estimated total time: 00:01:51, Estimated time left: 00:01:42\n",
            "2024-10-01 15:09:24,608 - INFO - Downloaded 9620/96243(10.0%) images - Elapsed time: 00:00:11, Estimated total time: 00:01:50, Estimated time left: 00:01:39\n",
            "2024-10-01 15:09:26,911 - INFO - Downloaded 11544/96243(12.0%) images - Elapsed time: 00:00:13, Estimated total time: 00:01:51, Estimated time left: 00:01:38\n",
            "2024-10-01 15:09:29,044 - INFO - Downloaded 13468/96243(14.0%) images - Elapsed time: 00:00:15, Estimated total time: 00:01:50, Estimated time left: 00:01:35\n",
            "2024-10-01 15:09:31,131 - INFO - Downloaded 15392/96243(16.0%) images - Elapsed time: 00:00:17, Estimated total time: 00:01:49, Estimated time left: 00:01:32\n",
            "2024-10-01 15:09:33,214 - INFO - Downloaded 17316/96243(18.0%) images - Elapsed time: 00:00:19, Estimated total time: 00:01:49, Estimated time left: 00:01:29\n",
            "2024-10-01 15:09:35,329 - INFO - Downloaded 19240/96243(20.0%) images - Elapsed time: 00:00:21, Estimated total time: 00:01:48, Estimated time left: 00:01:27\n",
            "2024-10-01 15:09:37,600 - INFO - Downloaded 21164/96243(22.0%) images - Elapsed time: 00:00:24, Estimated total time: 00:01:49, Estimated time left: 00:01:25\n",
            "2024-10-01 15:09:39,725 - INFO - Downloaded 23088/96243(24.0%) images - Elapsed time: 00:00:26, Estimated total time: 00:01:49, Estimated time left: 00:01:22\n",
            "2024-10-01 15:09:41,833 - INFO - Downloaded 25012/96243(26.0%) images - Elapsed time: 00:00:28, Estimated total time: 00:01:48, Estimated time left: 00:01:20\n",
            "2024-10-01 15:09:43,922 - INFO - Downloaded 26936/96243(28.0%) images - Elapsed time: 00:00:30, Estimated total time: 00:01:48, Estimated time left: 00:01:18\n",
            "2024-10-01 15:09:46,079 - INFO - Downloaded 28860/96243(30.0%) images - Elapsed time: 00:00:32, Estimated total time: 00:01:48, Estimated time left: 00:01:15\n",
            "2024-10-01 15:09:48,365 - INFO - Downloaded 30784/96243(32.0%) images - Elapsed time: 00:00:34, Estimated total time: 00:01:48, Estimated time left: 00:01:14\n",
            "2024-10-01 15:09:50,492 - INFO - Downloaded 32708/96243(34.0%) images - Elapsed time: 00:00:36, Estimated total time: 00:01:48, Estimated time left: 00:01:11\n",
            "2024-10-01 15:09:52,582 - INFO - Downloaded 34632/96243(36.0%) images - Elapsed time: 00:00:39, Estimated total time: 00:01:48, Estimated time left: 00:01:09\n",
            "2024-10-01 15:09:54,661 - INFO - Downloaded 36556/96243(38.0%) images - Elapsed time: 00:00:41, Estimated total time: 00:01:48, Estimated time left: 00:01:07\n",
            "2024-10-01 15:09:56,720 - INFO - Downloaded 38480/96243(40.0%) images - Elapsed time: 00:00:43, Estimated total time: 00:01:47, Estimated time left: 00:01:04\n",
            "2024-10-01 15:09:58,961 - INFO - Downloaded 40404/96243(42.0%) images - Elapsed time: 00:00:45, Estimated total time: 00:01:48, Estimated time left: 00:01:02\n",
            "2024-10-01 15:10:01,164 - INFO - Downloaded 42328/96243(44.0%) images - Elapsed time: 00:00:47, Estimated total time: 00:01:48, Estimated time left: 00:01:00\n",
            "2024-10-01 15:10:03,265 - INFO - Downloaded 44252/96243(46.0%) images - Elapsed time: 00:00:49, Estimated total time: 00:01:48, Estimated time left: 00:00:58\n",
            "2024-10-01 15:10:05,380 - INFO - Downloaded 46176/96243(48.0%) images - Elapsed time: 00:00:51, Estimated total time: 00:01:48, Estimated time left: 00:00:56\n",
            "2024-10-01 15:10:07,489 - INFO - Downloaded 48100/96243(50.0%) images - Elapsed time: 00:00:53, Estimated total time: 00:01:47, Estimated time left: 00:00:53\n",
            "2024-10-01 15:10:09,673 - INFO - Downloaded 50024/96243(52.0%) images - Elapsed time: 00:00:56, Estimated total time: 00:01:47, Estimated time left: 00:00:51\n",
            "2024-10-01 15:10:11,947 - INFO - Downloaded 51948/96243(54.0%) images - Elapsed time: 00:00:58, Estimated total time: 00:01:48, Estimated time left: 00:00:49\n",
            "2024-10-01 15:10:14,106 - INFO - Downloaded 53872/96243(56.0%) images - Elapsed time: 00:01:00, Estimated total time: 00:01:48, Estimated time left: 00:00:47\n",
            "2024-10-01 15:10:16,212 - INFO - Downloaded 55796/96243(58.0%) images - Elapsed time: 00:01:02, Estimated total time: 00:01:48, Estimated time left: 00:00:45\n",
            "2024-10-01 15:10:18,296 - INFO - Downloaded 57720/96243(60.0%) images - Elapsed time: 00:01:04, Estimated total time: 00:01:47, Estimated time left: 00:00:43\n",
            "2024-10-01 15:10:20,463 - INFO - Downloaded 59644/96243(62.0%) images - Elapsed time: 00:01:06, Estimated total time: 00:01:47, Estimated time left: 00:00:41\n",
            "2024-10-01 15:10:22,728 - INFO - Downloaded 61568/96243(64.0%) images - Elapsed time: 00:01:09, Estimated total time: 00:01:48, Estimated time left: 00:00:38\n",
            "2024-10-01 15:10:24,833 - INFO - Downloaded 63492/96243(66.0%) images - Elapsed time: 00:01:11, Estimated total time: 00:01:48, Estimated time left: 00:00:36\n",
            "2024-10-01 15:10:26,919 - INFO - Downloaded 65416/96243(68.0%) images - Elapsed time: 00:01:13, Estimated total time: 00:01:47, Estimated time left: 00:00:34\n",
            "2024-10-01 15:10:29,014 - INFO - Downloaded 67340/96243(70.0%) images - Elapsed time: 00:01:15, Estimated total time: 00:01:47, Estimated time left: 00:00:32\n",
            "2024-10-01 15:10:31,151 - INFO - Downloaded 69264/96243(72.0%) images - Elapsed time: 00:01:17, Estimated total time: 00:01:47, Estimated time left: 00:00:30\n",
            "2024-10-01 15:10:33,375 - INFO - Downloaded 71188/96243(74.0%) images - Elapsed time: 00:01:19, Estimated total time: 00:01:47, Estimated time left: 00:00:28\n",
            "2024-10-01 15:10:35,486 - INFO - Downloaded 73112/96243(76.0%) images - Elapsed time: 00:01:21, Estimated total time: 00:01:47, Estimated time left: 00:00:25\n",
            "2024-10-01 15:10:37,557 - INFO - Downloaded 75036/96243(78.0%) images - Elapsed time: 00:01:24, Estimated total time: 00:01:47, Estimated time left: 00:00:23\n",
            "2024-10-01 15:10:39,745 - INFO - Downloaded 76960/96243(80.0%) images - Elapsed time: 00:01:26, Estimated total time: 00:01:47, Estimated time left: 00:00:21\n",
            "2024-10-01 15:10:41,858 - INFO - Downloaded 78884/96243(82.0%) images - Elapsed time: 00:01:28, Estimated total time: 00:01:47, Estimated time left: 00:00:19\n",
            "2024-10-01 15:10:44,123 - INFO - Downloaded 80808/96243(84.0%) images - Elapsed time: 00:01:30, Estimated total time: 00:01:47, Estimated time left: 00:00:17\n",
            "2024-10-01 15:10:46,292 - INFO - Downloaded 82732/96243(86.0%) images - Elapsed time: 00:01:32, Estimated total time: 00:01:47, Estimated time left: 00:00:15\n",
            "2024-10-01 15:10:48,395 - INFO - Downloaded 84656/96243(88.0%) images - Elapsed time: 00:01:34, Estimated total time: 00:01:47, Estimated time left: 00:00:12\n",
            "2024-10-01 15:10:50,494 - INFO - Downloaded 86580/96243(90.0%) images - Elapsed time: 00:01:36, Estimated total time: 00:01:47, Estimated time left: 00:00:10\n",
            "2024-10-01 15:10:52,606 - INFO - Downloaded 88504/96243(92.0%) images - Elapsed time: 00:01:39, Estimated total time: 00:01:47, Estimated time left: 00:00:08\n",
            "2024-10-01 15:10:54,813 - INFO - Downloaded 90428/96243(94.0%) images - Elapsed time: 00:01:41, Estimated total time: 00:01:47, Estimated time left: 00:00:06\n",
            "2024-10-01 15:10:56,984 - INFO - Downloaded 92352/96243(96.0%) images - Elapsed time: 00:01:43, Estimated total time: 00:01:47, Estimated time left: 00:00:04\n",
            "2024-10-01 15:10:59,082 - INFO - Downloaded 94276/96243(98.0%) images - Elapsed time: 00:01:45, Estimated total time: 00:01:47, Estimated time left: 00:00:02\n",
            "2024-10-01 15:11:01,181 - INFO - Downloaded 96200/96243(100.0%) images - Elapsed time: 00:01:47, Estimated total time: 00:01:47, Estimated time left: 00:00:00\n",
            "2024-10-01 15:11:01,339 - INFO - Image download complete. Updating the dataframe.\n",
            "2024-10-01 15:11:02,564 - INFO - Dataframe updated. Processing downloaded images.\n",
            "2024-10-01 15:11:02,868 - INFO - Image processing complete.\n",
            "2024-10-01 15:11:46,835 - INFO - Final metrics pushed\n",
            "2024-10-01 15:11:46,836 - INFO - Task executed successfully\n",
            "Ready\n",
            "Dataset creation completed. Dataset ID: 426c58ac-0732-44dc-ac10-d734ffaada38\n"
          ]
        }
      ],
      "source": [
        "# Create the training dataset.\n",
        "training_dataset_name = f\"{training_data}-{suffix}\"\n",
        "print(f\"Creating training dataset ({training_dataset_name}):\")\n",
        "training_dataset = marqtune_client.create_dataset(\n",
        "    dataset_name=training_dataset_name,\n",
        "    file_path=training_data,\n",
        "    dataset_type=DatasetType.TRAINING,\n",
        "    data_schema=data_schema,\n",
        "    query_columns=[\"query\"],\n",
        "    result_columns=[\"title\", \"image\"],\n",
        "    # setting wait_for_completion=True will make this a blocking call and will also print logs interactively\n",
        "    wait_for_completion=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFhSdvSPUWPA"
      },
      "source": [
        "We do the same for the evaluation dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dJJ2BneowC4x",
        "outputId": "071729ca-7ab2-4233-eadd-12bfe5349c91"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating evaluation dataset (gs_25k_eval.csv-d166c36f):\n",
            "Dataset was initialised. Dataset ID: 9744d86a-505c-4a32-bb55-eec30826f00f\n",
            "Attempting to upload file...\n",
            "File uploaded successfully. Job will start soon\n",
            "Uploading..\n",
            "Creating: Provisioning...\n",
            "Creating: Running\n",
            "2024-10-01 15:13:07,903 - INFO - Initialising task\n",
            "2024-10-01 15:13:07,971 - INFO - Downloading files for task 9744d86a-505c-4a32-bb55-eec30826f00f\n",
            "2024-10-01 15:13:08,197 - INFO - File download is completed\n",
            "2024-10-01 15:13:08,199 - INFO - Preparing dataset with {'input_file': 'dataset/9744d86a-505c-4a32-bb55-eec30826f00f/dataset.csv', 'data_schema': {'query': 'text', 'title': 'text', 'image': 'image_pointer', 'score': 'score'}, 'output_path': '9744d86a-505c-4a32-bb55-eec30826f00f', 'dataset_type': 'evaluation', 'result_columns': ['title', 'image'], 'image_download_headers': None, 'logger': <Logger __main__ (DEBUG)>, 'metrics_collector': <clients.cw_client.CWClient object at 0xffff91cd1910>, 'query_columns': ['query']}\n",
            "2024-10-01 15:13:08,265 - INFO - Total rows after cleaning up dataset: 50000, rows dropped: 0\n",
            "2024-10-01 15:13:08,266 - INFO - Initiating file processing. It will validate every row and download images. Please wait, this process may take a while.\n",
            "2024-10-01 15:13:08,273 - INFO - Image download started for 24757 images.\n",
            "2024-10-01 15:13:09,279 - INFO - Downloaded 495/24757(2.0%) images - Elapsed time: 00:00:01, Estimated total time: 00:00:50, Estimated time left: 00:00:49\n",
            "2024-10-01 15:13:09,854 - INFO - Downloaded 990/24757(4.0%) images - Elapsed time: 00:00:01, Estimated total time: 00:00:39, Estimated time left: 00:00:37\n",
            "2024-10-01 15:13:10,428 - INFO - Downloaded 1485/24757(6.0%) images - Elapsed time: 00:00:02, Estimated total time: 00:00:35, Estimated time left: 00:00:33\n",
            "2024-10-01 15:13:11,002 - INFO - Downloaded 1980/24757(8.0%) images - Elapsed time: 00:00:02, Estimated total time: 00:00:34, Estimated time left: 00:00:31\n",
            "2024-10-01 15:13:11,605 - INFO - Downloaded 2475/24757(10.0%) images - Elapsed time: 00:00:03, Estimated total time: 00:00:33, Estimated time left: 00:00:29\n",
            "2024-10-01 15:13:12,186 - INFO - Downloaded 2970/24757(12.0%) images - Elapsed time: 00:00:03, Estimated total time: 00:00:32, Estimated time left: 00:00:28\n",
            "2024-10-01 15:13:12,746 - INFO - Downloaded 3465/24757(14.0%) images - Elapsed time: 00:00:04, Estimated total time: 00:00:31, Estimated time left: 00:00:27\n",
            "2024-10-01 15:13:13,321 - INFO - Downloaded 3960/24757(16.0%) images - Elapsed time: 00:00:05, Estimated total time: 00:00:31, Estimated time left: 00:00:26\n",
            "2024-10-01 15:13:13,895 - INFO - Downloaded 4455/24757(18.0%) images - Elapsed time: 00:00:05, Estimated total time: 00:00:31, Estimated time left: 00:00:25\n",
            "2024-10-01 15:13:14,472 - INFO - Downloaded 4950/24757(20.0%) images - Elapsed time: 00:00:06, Estimated total time: 00:00:30, Estimated time left: 00:00:24\n",
            "2024-10-01 15:13:15,044 - INFO - Downloaded 5445/24757(22.0%) images - Elapsed time: 00:00:06, Estimated total time: 00:00:30, Estimated time left: 00:00:24\n",
            "2024-10-01 15:13:15,609 - INFO - Downloaded 5940/24757(24.0%) images - Elapsed time: 00:00:07, Estimated total time: 00:00:30, Estimated time left: 00:00:23\n",
            "2024-10-01 15:13:16,183 - INFO - Downloaded 6435/24757(26.0%) images - Elapsed time: 00:00:07, Estimated total time: 00:00:30, Estimated time left: 00:00:22\n",
            "2024-10-01 15:13:16,726 - INFO - Downloaded 6930/24757(28.0%) images - Elapsed time: 00:00:08, Estimated total time: 00:00:30, Estimated time left: 00:00:21\n",
            "2024-10-01 15:13:17,275 - INFO - Downloaded 7425/24757(30.0%) images - Elapsed time: 00:00:08, Estimated total time: 00:00:30, Estimated time left: 00:00:21\n",
            "2024-10-01 15:13:17,829 - INFO - Downloaded 7920/24757(32.0%) images - Elapsed time: 00:00:09, Estimated total time: 00:00:29, Estimated time left: 00:00:20\n",
            "2024-10-01 15:13:18,362 - INFO - Downloaded 8415/24757(34.0%) images - Elapsed time: 00:00:10, Estimated total time: 00:00:29, Estimated time left: 00:00:19\n",
            "2024-10-01 15:13:18,908 - INFO - Downloaded 8910/24757(36.0%) images - Elapsed time: 00:00:10, Estimated total time: 00:00:29, Estimated time left: 00:00:18\n",
            "2024-10-01 15:13:19,502 - INFO - Downloaded 9405/24757(38.0%) images - Elapsed time: 00:00:11, Estimated total time: 00:00:29, Estimated time left: 00:00:18\n",
            "2024-10-01 15:13:20,140 - INFO - Downloaded 9900/24757(40.0%) images - Elapsed time: 00:00:11, Estimated total time: 00:00:29, Estimated time left: 00:00:17\n",
            "2024-10-01 15:13:20,713 - INFO - Downloaded 10395/24757(42.0%) images - Elapsed time: 00:00:12, Estimated total time: 00:00:29, Estimated time left: 00:00:17\n",
            "2024-10-01 15:13:21,251 - INFO - Downloaded 10890/24757(44.0%) images - Elapsed time: 00:00:12, Estimated total time: 00:00:29, Estimated time left: 00:00:16\n",
            "2024-10-01 15:13:21,796 - INFO - Downloaded 11385/24757(46.0%) images - Elapsed time: 00:00:13, Estimated total time: 00:00:29, Estimated time left: 00:00:15\n",
            "2024-10-01 15:13:22,346 - INFO - Downloaded 11880/24757(48.0%) images - Elapsed time: 00:00:14, Estimated total time: 00:00:29, Estimated time left: 00:00:15\n",
            "2024-10-01 15:13:22,886 - INFO - Downloaded 12375/24757(50.0%) images - Elapsed time: 00:00:14, Estimated total time: 00:00:29, Estimated time left: 00:00:14\n",
            "2024-10-01 15:13:23,446 - INFO - Downloaded 12870/24757(52.0%) images - Elapsed time: 00:00:15, Estimated total time: 00:00:29, Estimated time left: 00:00:14\n",
            "2024-10-01 15:13:23,988 - INFO - Downloaded 13365/24757(54.0%) images - Elapsed time: 00:00:15, Estimated total time: 00:00:29, Estimated time left: 00:00:13\n",
            "2024-10-01 15:13:24,533 - INFO - Downloaded 13860/24757(56.0%) images - Elapsed time: 00:00:16, Estimated total time: 00:00:29, Estimated time left: 00:00:12\n",
            "2024-10-01 15:13:25,075 - INFO - Downloaded 14355/24757(58.0%) images - Elapsed time: 00:00:16, Estimated total time: 00:00:28, Estimated time left: 00:00:12\n",
            "2024-10-01 15:13:25,614 - INFO - Downloaded 14850/24757(60.0%) images - Elapsed time: 00:00:17, Estimated total time: 00:00:28, Estimated time left: 00:00:11\n",
            "2024-10-01 15:13:26,152 - INFO - Downloaded 15345/24757(62.0%) images - Elapsed time: 00:00:17, Estimated total time: 00:00:28, Estimated time left: 00:00:10\n",
            "2024-10-01 15:13:26,702 - INFO - Downloaded 15840/24757(64.0%) images - Elapsed time: 00:00:18, Estimated total time: 00:00:28, Estimated time left: 00:00:10\n",
            "2024-10-01 15:13:27,258 - INFO - Downloaded 16335/24757(66.0%) images - Elapsed time: 00:00:18, Estimated total time: 00:00:28, Estimated time left: 00:00:09\n",
            "2024-10-01 15:13:27,815 - INFO - Downloaded 16830/24757(68.0%) images - Elapsed time: 00:00:19, Estimated total time: 00:00:28, Estimated time left: 00:00:09\n",
            "2024-10-01 15:13:28,363 - INFO - Downloaded 17325/24757(70.0%) images - Elapsed time: 00:00:20, Estimated total time: 00:00:28, Estimated time left: 00:00:08\n",
            "2024-10-01 15:13:28,896 - INFO - Downloaded 17820/24757(72.0%) images - Elapsed time: 00:00:20, Estimated total time: 00:00:28, Estimated time left: 00:00:08\n",
            "2024-10-01 15:13:29,430 - INFO - Downloaded 18315/24757(74.0%) images - Elapsed time: 00:00:21, Estimated total time: 00:00:28, Estimated time left: 00:00:07\n",
            "2024-10-01 15:13:29,977 - INFO - Downloaded 18810/24757(76.0%) images - Elapsed time: 00:00:21, Estimated total time: 00:00:28, Estimated time left: 00:00:06\n",
            "2024-10-01 15:13:30,569 - INFO - Downloaded 19305/24757(78.0%) images - Elapsed time: 00:00:22, Estimated total time: 00:00:28, Estimated time left: 00:00:06\n",
            "2024-10-01 15:13:31,186 - INFO - Downloaded 19800/24757(80.0%) images - Elapsed time: 00:00:22, Estimated total time: 00:00:28, Estimated time left: 00:00:05\n",
            "2024-10-01 15:13:31,770 - INFO - Downloaded 20295/24757(82.0%) images - Elapsed time: 00:00:23, Estimated total time: 00:00:28, Estimated time left: 00:00:05\n",
            "2024-10-01 15:13:32,311 - INFO - Downloaded 20790/24757(84.0%) images - Elapsed time: 00:00:24, Estimated total time: 00:00:28, Estimated time left: 00:00:04\n",
            "2024-10-01 15:13:32,863 - INFO - Downloaded 21285/24757(86.0%) images - Elapsed time: 00:00:24, Estimated total time: 00:00:28, Estimated time left: 00:00:04\n",
            "2024-10-01 15:13:33,407 - INFO - Downloaded 21780/24757(88.0%) images - Elapsed time: 00:00:25, Estimated total time: 00:00:28, Estimated time left: 00:00:03\n",
            "2024-10-01 15:13:33,950 - INFO - Downloaded 22275/24757(90.0%) images - Elapsed time: 00:00:25, Estimated total time: 00:00:28, Estimated time left: 00:00:02\n",
            "2024-10-01 15:13:34,496 - INFO - Downloaded 22770/24757(92.0%) images - Elapsed time: 00:00:26, Estimated total time: 00:00:28, Estimated time left: 00:00:02\n",
            "2024-10-01 15:13:35,033 - INFO - Downloaded 23265/24757(94.0%) images - Elapsed time: 00:00:26, Estimated total time: 00:00:28, Estimated time left: 00:00:01\n",
            "2024-10-01 15:13:35,571 - INFO - Downloaded 23760/24757(96.0%) images - Elapsed time: 00:00:27, Estimated total time: 00:00:28, Estimated time left: 00:00:01\n",
            "2024-10-01 15:13:36,119 - INFO - Downloaded 24255/24757(98.0%) images - Elapsed time: 00:00:27, Estimated total time: 00:00:28, Estimated time left: 00:00:00\n",
            "2024-10-01 15:13:36,644 - INFO - Downloaded 24750/24757(100.0%) images - Elapsed time: 00:00:28, Estimated total time: 00:00:28, Estimated time left: 00:00:00\n",
            "2024-10-01 15:13:36,786 - INFO - Image download complete. Updating the dataframe.\n",
            "2024-10-01 15:13:37,091 - INFO - Dataframe updated. Processing downloaded images.\n",
            "2024-10-01 15:13:37,168 - INFO - Image processing complete.\n",
            "Ready\n",
            "Dataset creation completed. Dataset ID: 9744d86a-505c-4a32-bb55-eec30826f00f\n"
          ]
        }
      ],
      "source": [
        "# Similarly we create the Evaluation dataset.\n",
        "eval_dataset_name = f\"{eval_data}-{suffix}\"\n",
        "print(f\"Creating evaluation dataset ({eval_dataset_name}):\")\n",
        "eval_dataset = marqtune_client.create_dataset(\n",
        "    dataset_name=eval_dataset_name,\n",
        "    file_path=eval_data,\n",
        "    dataset_type=DatasetType.EVALUATION,\n",
        "    data_schema=data_schema,\n",
        "    query_columns=[\"query\"],\n",
        "    result_columns=[\"title\", \"image\"],\n",
        "    wait_for_completion=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgcr0EPxVV-R"
      },
      "source": [
        "### **4. Model Tuning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7U5elIMyUaUX"
      },
      "source": [
        "Now we're ready to train a model. To do so we define a few training hyper parameters. In this example we've set some parameters that work well with the sample dataset but you are encouraged to experiment with these values for your own datasets.\n",
        "\n",
        "In our example for the base pre-trained open clip model, we've chosen to use `ViT-B-32 - laion400m_e31` which is a good model to start with as it gives us good performance with low latency/memory usage. We have previously published a guide to help you [choose the right model](https://www.marqo.ai/blog/benchmarking-models-for-multimodal-search) for your use case."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "M2QNenCLwHNb"
      },
      "outputs": [],
      "source": [
        "# Setup training hyper parameters:\n",
        "training_params = {\n",
        "    \"leftKeys\": [\"query\"],\n",
        "    \"leftWeights\": [1],\n",
        "    \"rightKeys\": [\"image\", \"title\"],\n",
        "    \"rightWeights\": [0.9, 0.1],\n",
        "    \"weightKey\": \"score\",\n",
        "    \"epochs\": 5,\n",
        "}\n",
        "\n",
        "base_model = \"ViT-B-32\"\n",
        "base_checkpoint = \"laion2b_s34b_b79k\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIXDKOWLUfS_"
      },
      "source": [
        "The `training_params` dictionary is used to define the training hyperparameters. We've chosen a minimal set of hyperparameters to get you started - primarily the left/right keys define the columns in the input CSV that we're training on. You can experiment on these parameters yourself, refer to the [Training Parameters documentation](https://docs.marqo.ai/2.10/Marqtune/API/evaluation/evaluation_parameters/) for documentation on these and other parameters available for training.\n",
        "\n",
        "This training will take a while to complete, though you may choose to run it faster using more powerful hardware: `instance_type=InstanceType.PERFORMANCE`.\n",
        "\n",
        "It's also worth noting that once training has been successfully kicked off in Marqtune it will continue till completion no matter what happens to your local client session. On start the logs will show the new model id that can be used to identify your model - copy this id so that if your local console disconnects for some reason during training you can always resume the rest of this guide after loading the completed model: `tuned_model = marqtune_client.model('<model id>')`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "d_vIrvhXa0gS",
        "outputId": "46adc31e-9505-4157-941f-34a57749ddbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training a new model (gs_100k_training.csv-model-d166c36f):\n",
            "Model creation was initialised. Model ID: a4f61808-819f-4576-8fd2-30144047a1d4\n",
            "Initializing.\n",
            "Creating: Provisioning...\n",
            "Creating: Running\n",
            "2024-10-01 15:14:42,115 - INFO - Initialising task\n",
            "2024-10-01 15:14:42,188 - INFO - Downloading files for task a4f61808-819f-4576-8fd2-30144047a1d4\n",
            "2024-10-01 15:15:17,857 - INFO - File download is completed\n",
            "2024-10-01 15:15:17,935 - INFO - Initializing training job for model ViT-B-32 and dataset 426c58ac-0732-44dc-ac10-d734ffaada38. Please wait, it may take some time.\n",
            "METRIC: imagesPreprocessingTime=29;\n",
            "Executing training job with 1 GPUs.\n",
            "Torchrun command:  ['torchrun', '--nproc_per_node', '1', 'main.py', '--', '--left-keys', \"['query']\", '--left-weights', '[1]', '--right-keys', \"['image', 'title']\", '--right-weights', '[0.9, 0.1]', '--weight-key', 'score', '--epochs', '5', '--train-data', '/app/src/data/label.csv', '--img-or-txt', \"[['txt'], ['img', 'txt']]\", '--id-keys', \"['query', 'image']\", '--dataset-type', 'weighted_csv', '--output-format', 'pt', '--model', 'ViT-B-32', '--pretrained', 'laion2b_s34b_b79k', '--logs', '/app/logs', '--name', 'model']\n",
            "2024-10-01,15:18:03 | INFO | Running with a single process. Device cuda:0.\n",
            "2024-10-01,15:18:03 | INFO | Loaded ViT-B-32 model config.\n",
            "Downloading 'open_clip_pytorch_model.bin' to '/root/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/blobs/1bd3c7172de5b207ceac554f5ab5266166f3b9baccc9af5989bc801016d080ad.incomplete'\n",
            "2024-10-01,15:18:08 | INFO | Downloading 'open_clip_pytorch_model.bin' to '/root/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/blobs/1bd3c7172de5b207ceac554f5ab5266166f3b9baccc9af5989bc801016d080ad.incomplete'\n",
            "Download complete. Moving file to /root/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/blobs/1bd3c7172de5b207ceac554f5ab5266166f3b9baccc9af5989bc801016d080ad\n",
            "2024-10-01,15:18:09 | INFO | Download complete. Moving file to /root/.cache/huggingface/hub/models--laion--CLIP-ViT-B-32-laion2B-s34B-b79K/blobs/1bd3c7172de5b207ceac554f5ab5266166f3b9baccc9af5989bc801016d080ad\n",
            "2024-10-01,15:18:09 | INFO | Loading pretrained ViT-B-32 weights (laion2b_s34b_b79k).\n",
            "/usr/local/lib/python3.8/site-packages/open_clip/factory.py:129: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(checkpoint_path, map_location=map_location)\n",
            "2024-10-01,15:18:09 | INFO | Model:\n",
            "2024-10-01,15:18:09 | INFO | multi_field_model(\n",
            "  (model): CLIP(\n",
            "    (visual): VisionTransformer(\n",
            "      (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
            "      (patch_dropout): Identity()\n",
            "      (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "      (transformer): Transformer(\n",
            "        (resblocks): ModuleList(\n",
            "          (0-11): 12 x ResidualAttentionBlock(\n",
            "            (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (attn): MultiheadAttention(\n",
            "              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
            "            )\n",
            "            (ls_1): Identity()\n",
            "            (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "            (mlp): Sequential(\n",
            "              (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (gelu): GELU(approximate='none')\n",
            "              (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            )\n",
            "            (ls_2): Identity()\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "      (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (transformer): Transformer(\n",
            "      (resblocks): ModuleList(\n",
            "        (0-11): 12 x ResidualAttentionBlock(\n",
            "          (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (attn): MultiheadAttention(\n",
            "            (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (ls_1): Identity()\n",
            "          (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (mlp): Sequential(\n",
            "            (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
            "            (gelu): GELU(approximate='none')\n",
            "            (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          )\n",
            "          (ls_2): Identity()\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (token_embedding): Embedding(49408, 512)\n",
            "    (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            ")\n",
            "2024-10-01,15:18:09 | INFO | Params:\n",
            "2024-10-01,15:18:09 | INFO |   __annotations__: {'cluster_sampling': <class 'bool'>, 'id_keys': <class 'str'>, 'context_length': <class 'str'>, 'logit_scale': <class 'float'>, 'logit_bias': <class 'float'>, 'sq_interval': <class 'int'>, 'sq_logit_scale': <class 'float'>, 'left_keys': <class 'str'>, 'right_keys': <class 'str'>, 'img_or_txt': <class 'str'>, 'left_weights': <class 'str'>, 'right_weights': <class 'str'>, 'weight_key': <class 'str'>, 'weighted_loss': <class 'str'>, 'train_data': <class 'str'>, 'train_data_sq': <class 'str'>, 'train_data_upsampling_factors': <class 'str'>, 'val_data': <class 'str'>, 'train_num_samples': <class 'int'>, 'val_num_samples': <class 'int'>, 'dataset_type': <class 'str'>, 'dataset_resampled': <class 'bool'>, 'csv_separator': <class 'str'>, 'imagenet_val': <class 'str'>, 'imagenet_v2': <class 'str'>, 'logs': <class 'str'>, 'log_local': <class 'bool'>, 'name': <class 'str'>, 'workers': <class 'int'>, 'batch_size': <class 'int'>, 'epochs': <class 'int'>, 'epochs_cooldown': <class 'int'>, 'lr': <class 'float'>, 'beta1': <class 'float'>, 'beta2': <class 'float'>, 'eps': <class 'float'>, 'wd': <class 'float'>, 'warmup': <class 'int'>, 'use_bn_sync': <class 'bool'>, 'skip_scheduler': <class 'bool'>, 'lr_scheduler': <class 'str'>, 'lr_cooldown_end': <class 'float'>, 'lr_cooldown_power': <class 'float'>, 'save_frequency': <class 'int'>, 'save_most_recent': <class 'bool'>, 'zeroshot_frequency': <class 'int'>, 'val_frequency': <class 'int'>, 'resume': <class 'str'>, 'precision': <class 'str'>, 'model': <class 'str'>, 'pretrained': <class 'str'>, 'pretrained_image': <class 'bool'>, 'lock_image': <class 'bool'>, 'lock_image_unlocked_groups': <class 'int'>, 'lock_image_freeze_bn_stats': <class 'bool'>, 'image_mean': typing.List[float], 'image_std': typing.List[float], 'aug_cfg': typing.Dict[str, typing.Any], 'grad_checkpointing': <class 'bool'>, 'local_loss': <class 'bool'>, 'gather_with_grad': <class 'bool'>, 'force_image_size': typing.List[int], 'force_quick_gelu': <class 'bool'>, 'force_patch_dropout': <class 'float'>, 'force_custom_text': <class 'bool'>, 'torchscript': <class 'bool'>, 'trace': <class 'bool'>, 'accum_freq': <class 'int'>, 'dist_url': <class 'str'>, 'dist_backend': <class 'str'>, 'report_to': <class 'str'>, 'wandb_notes': <class 'str'>, 'wandb_project_name': <class 'str'>, 'debug': <class 'bool'>, 'copy_codebase': <class 'bool'>, 'horovod': <class 'bool'>, 'ddp_static_graph': <class 'bool'>, 'no_set_device_rank': <class 'bool'>, 'seed': <class 'int'>, 'grad_clip_norm': <class 'float'>, 'lock_text': <class 'bool'>, 'lock_text_unlocked_layers': <class 'int'>, 'lock_text_freeze_layer_norm': <class 'bool'>, 'log_every_n_steps': <class 'int'>, 'coca_caption_loss_weight': <class 'float'>, 'coca_contrastive_loss_weight': <class 'float'>, 'remote_sync': <class 'str'>, 'remote_sync_frequency': <class 'int'>, 'remote_sync_protocol': <class 'str'>, 'delete_previous_checkpoint': <class 'bool'>, 'distill_model': <class 'str'>, 'distill_pretrained': <class 'str'>, 'use_bnb_linear': <class 'str'>, 'frozen_right': <class 'bool'>, 'checkpoint_path': <class 'str'>, 'dynamic_batch_size': <class 'bool'>}\n",
            "2024-10-01,15:18:09 | INFO |   __doc__: \n",
            "    This class inherits from argparse.Namespace and is used to store the arguments passed to the training script.\n",
            "    \n",
            "2024-10-01,15:18:09 | INFO |   __module__: params\n",
            "2024-10-01,15:18:09 | INFO |   accum_freq: 1\n",
            "2024-10-01,15:18:09 | INFO |   aug_cfg: {}\n",
            "2024-10-01,15:18:09 | INFO |   batch_size: 256\n",
            "2024-10-01,15:18:09 | INFO |   beta1: 0.9\n",
            "2024-10-01,15:18:09 | INFO |   beta2: 0.98\n",
            "2024-10-01,15:18:09 | INFO |   checkpoint_path: /app/logs/model/checkpoints\n",
            "2024-10-01,15:18:09 | INFO |   cluster_sampling: False\n",
            "2024-10-01,15:18:09 | INFO |   coca_caption_loss_weight: 2.0\n",
            "2024-10-01,15:18:09 | INFO |   coca_contrastive_loss_weight: 1.0\n",
            "2024-10-01,15:18:09 | INFO |   context_length: [[77], [77, 77]]\n",
            "2024-10-01,15:18:09 | INFO |   copy_codebase: False\n",
            "2024-10-01,15:18:09 | INFO |   csv_separator: \t\n",
            "2024-10-01,15:18:09 | INFO |   dataset_resampled: False\n",
            "2024-10-01,15:18:09 | INFO |   dataset_type: weighted_csv\n",
            "2024-10-01,15:18:09 | INFO |   ddp_static_graph: False\n",
            "2024-10-01,15:18:09 | INFO |   debug: False\n",
            "2024-10-01,15:18:09 | INFO |   delete_previous_checkpoint: False\n",
            "2024-10-01,15:18:09 | INFO |   device: cuda:0\n",
            "2024-10-01,15:18:09 | INFO |   dist_backend: nccl\n",
            "2024-10-01,15:18:09 | INFO |   dist_url: env://\n",
            "2024-10-01,15:18:09 | INFO |   distill: False\n",
            "2024-10-01,15:18:09 | INFO |   distill_model: None\n",
            "2024-10-01,15:18:09 | INFO |   distill_pretrained: None\n",
            "2024-10-01,15:18:09 | INFO |   distributed: False\n",
            "2024-10-01,15:18:09 | INFO |   dynamic_batch_size: False\n",
            "2024-10-01,15:18:09 | INFO |   epochs: 5\n",
            "2024-10-01,15:18:09 | INFO |   epochs_cooldown: None\n",
            "2024-10-01,15:18:09 | INFO |   eps: 1e-06\n",
            "2024-10-01,15:18:09 | INFO |   force_custom_text: False\n",
            "2024-10-01,15:18:09 | INFO |   force_image_size: None\n",
            "2024-10-01,15:18:09 | INFO |   force_patch_dropout: None\n",
            "2024-10-01,15:18:09 | INFO |   force_quick_gelu: False\n",
            "2024-10-01,15:18:09 | INFO |   frozen_right: False\n",
            "2024-10-01,15:18:09 | INFO |   gather_with_grad: True\n",
            "2024-10-01,15:18:09 | INFO |   grad_checkpointing: True\n",
            "2024-10-01,15:18:09 | INFO |   grad_clip_norm: None\n",
            "2024-10-01,15:18:09 | INFO |   horovod: False\n",
            "2024-10-01,15:18:09 | INFO |   id_keys: ['query', 'image']\n",
            "2024-10-01,15:18:09 | INFO |   image_mean: None\n",
            "2024-10-01,15:18:09 | INFO |   image_std: None\n",
            "2024-10-01,15:18:09 | INFO |   imagenet_v2: None\n",
            "2024-10-01,15:18:09 | INFO |   imagenet_val: None\n",
            "2024-10-01,15:18:09 | INFO |   img_or_txt: [['txt'], ['img', 'txt']]\n",
            "2024-10-01,15:18:09 | INFO |   left_keys: ['query']\n",
            "2024-10-01,15:18:09 | INFO |   left_weights: [1]\n",
            "2024-10-01,15:18:09 | INFO |   local_loss: False\n",
            "2024-10-01,15:18:09 | INFO |   local_rank: 0\n",
            "2024-10-01,15:18:09 | INFO |   lock_image: False\n",
            "2024-10-01,15:18:09 | INFO |   lock_image_freeze_bn_stats: False\n",
            "2024-10-01,15:18:09 | INFO |   lock_image_unlocked_groups: 0\n",
            "2024-10-01,15:18:09 | INFO |   lock_text: False\n",
            "2024-10-01,15:18:09 | INFO |   lock_text_freeze_layer_norm: False\n",
            "2024-10-01,15:18:09 | INFO |   lock_text_unlocked_layers: 0\n",
            "2024-10-01,15:18:09 | INFO |   log_every_n_steps: 100\n",
            "2024-10-01,15:18:09 | INFO |   log_level: 20\n",
            "2024-10-01,15:18:09 | INFO |   log_local: False\n",
            "2024-10-01,15:18:09 | INFO |   log_path: /app/logs/model/out.log\n",
            "2024-10-01,15:18:09 | INFO |   logit_bias: None\n",
            "2024-10-01,15:18:09 | INFO |   logit_scale: None\n",
            "2024-10-01,15:18:09 | INFO |   logs: /app/logs\n",
            "2024-10-01,15:18:09 | INFO |   lr: 0.0005\n",
            "2024-10-01,15:18:09 | INFO |   lr_cooldown_end: 0.0\n",
            "2024-10-01,15:18:09 | INFO |   lr_cooldown_power: 1.0\n",
            "2024-10-01,15:18:09 | INFO |   lr_scheduler: cosine\n",
            "2024-10-01,15:18:09 | INFO |   meta_data: None\n",
            "2024-10-01,15:18:09 | INFO |   model: ViT-B-32\n",
            "2024-10-01,15:18:09 | INFO |   name: model\n",
            "2024-10-01,15:18:09 | INFO |   no_set_device_rank: False\n",
            "2024-10-01,15:18:09 | INFO |   output_format: pt\n",
            "2024-10-01,15:18:09 | INFO |   precision: amp\n",
            "2024-10-01,15:18:09 | INFO |   pretrained: laion2b_s34b_b79k\n",
            "2024-10-01,15:18:09 | INFO |   pretrained_image: False\n",
            "2024-10-01,15:18:09 | INFO |   rank: 0\n",
            "2024-10-01,15:18:09 | INFO |   remote_sync: None\n",
            "2024-10-01,15:18:09 | INFO |   remote_sync_frequency: 300\n",
            "2024-10-01,15:18:09 | INFO |   remote_sync_protocol: s3\n",
            "2024-10-01,15:18:09 | INFO |   report_to: \n",
            "2024-10-01,15:18:09 | INFO |   resume: None\n",
            "2024-10-01,15:18:09 | INFO |   right_keys: ['image', 'title']\n",
            "2024-10-01,15:18:09 | INFO |   right_weights: [0.9, 0.1]\n",
            "2024-10-01,15:18:09 | INFO |   save_frequency: 1\n",
            "2024-10-01,15:18:09 | INFO |   save_most_recent: False\n",
            "2024-10-01,15:18:09 | INFO |   seed: 0\n",
            "2024-10-01,15:18:09 | INFO |   skip_scheduler: False\n",
            "2024-10-01,15:18:09 | INFO |   sq_interval: 2\n",
            "2024-10-01,15:18:09 | INFO |   sq_logit_scale: 1.5\n",
            "2024-10-01,15:18:09 | INFO |   tensorboard: False\n",
            "2024-10-01,15:18:09 | INFO |   tensorboard_path: \n",
            "2024-10-01,15:18:09 | INFO |   torchscript: False\n",
            "2024-10-01,15:18:09 | INFO |   trace: False\n",
            "2024-10-01,15:18:09 | INFO |   train_data: /app/src/data/label.csv\n",
            "2024-10-01,15:18:09 | INFO |   train_data_sq: None\n",
            "2024-10-01,15:18:09 | INFO |   train_data_upsampling_factors: None\n",
            "2024-10-01,15:18:09 | INFO |   train_num_samples: None\n",
            "2024-10-01,15:18:09 | INFO |   unique_batch_sampling: False\n",
            "2024-10-01,15:18:09 | INFO |   use_bn_sync: False\n",
            "2024-10-01,15:18:09 | INFO |   use_bnb_linear: None\n",
            "2024-10-01,15:18:09 | INFO |   val_data: None\n",
            "2024-10-01,15:18:09 | INFO |   val_frequency: 1\n",
            "2024-10-01,15:18:09 | INFO |   val_num_samples: None\n",
            "2024-10-01,15:18:09 | INFO |   wandb: False\n",
            "2024-10-01,15:18:09 | INFO |   wandb_notes: \n",
            "2024-10-01,15:18:09 | INFO |   wandb_project_name: open-clip\n",
            "2024-10-01,15:18:09 | INFO |   warmup: 10000\n",
            "2024-10-01,15:18:09 | INFO |   wd: 0.2\n",
            "2024-10-01,15:18:09 | INFO |   weight_key: score\n",
            "2024-10-01,15:18:09 | INFO |   weighted_loss: ce\n",
            "2024-10-01,15:18:09 | INFO |   workers: 5\n",
            "2024-10-01,15:18:09 | INFO |   world_size: 1\n",
            "2024-10-01,15:18:09 | INFO |   zeroshot_frequency: 2\n",
            "main.py:444: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler() if args.precision == \"amp\" else None\n",
            "Using Pyarrow instead of List\n",
            "2024-10-01,15:18:10 | INFO | Start epoch 0\n",
            "/app/ml/code/weighted_training/utils.py:348: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():\n",
            "/usr/local/lib/python3.8/site-packages/torch/_dynamo/eval_frame.py:600: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  return fn(*args, **kwargs)\n",
            "/usr/local/lib/python3.8/site-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "2024-10-01,15:19:01 | INFO | Train Epoch: 0 [   256/100000 (0%)] Data (t): 4.352 Batch (t): 51.305, 4.98980/s, 4.98980/s/gpu LR: 0.000000 Logit Scale: 100.000, Logit Bias: 0.000, Txt_img_0_0_loss: 1.2694 (1.2694) Txt_txt_0_1_loss: 4.1798 (4.1798) Weighted_mean_loss: 1.0293 (1.0293) Loss: 1.9370 (1.9370)\n",
            "2024-10-01,15:20:27 | INFO | Train Epoch: 0 [ 25856/100000 (26%)] Data (t): 0.000 Batch (t): 0.851, 313.772/s, 313.772/s/gpu LR: 0.000005 Logit Scale: 99.985, Logit Bias: 0.000, Txt_img_0_0_loss: 0.65430 (0.96185) Txt_txt_0_1_loss: 0.45087 (2.3153) Weighted_mean_loss: 0.47781 (0.75355) Loss: 0.55932 (1.2481)\n",
            "2024-10-01,15:21:48 | INFO | Train Epoch: 0 [ 51456/100000 (52%)] Data (t): 0.001 Batch (t): 0.816, 313.477/s, 313.477/s/gpu LR: 0.000010 Logit Scale: 99.977, Logit Bias: 0.000, Txt_img_0_0_loss: 0.59961 (0.84110) Txt_txt_0_1_loss: 0.28986 (1.6402) Weighted_mean_loss: 0.40798 (0.63836) Loss: 0.47427 (0.99019)\n",
            "2024-10-01,15:23:10 | INFO | Train Epoch: 0 [ 77056/100000 (77%)] Data (t): 0.000 Batch (t): 0.817, 313.580/s, 313.580/s/gpu LR: 0.000015 Logit Scale: 99.958, Logit Bias: 0.000, Txt_img_0_0_loss: 0.77311 (0.82411) Txt_txt_0_1_loss: 0.27735 (1.2995) Weighted_mean_loss: 0.50110 (0.60405) Loss: 0.58116 (0.88793)\n",
            "2024-10-01,15:24:23 | INFO | Train Epoch: 0 [ 99840/100000 (100%)] Data (t): 0.001 Batch (t): 0.816, 314.452/s, 314.452/s/gpu LR: 0.000019 Logit Scale: 99.929, Logit Bias: 0.000, Txt_img_0_0_loss: 0.84461 (0.82821) Txt_txt_0_1_loss: 0.37151 (1.1139) Weighted_mean_loss: 0.54197 (0.59163) Loss: 0.65068 (0.84048)\n",
            "METRIC: epochTime=372;\n",
            "2024-10-01,15:24:24 | INFO | Start epoch 1\n",
            "2024-10-01,15:24:27 | INFO | Train Epoch: 1 [   256/100000 (0%)] Data (t): 2.045 Batch (t): 2.848, 89.8843/s, 89.8843/s/gpu LR: 0.000020 Logit Scale: 99.928, Logit Bias: 0.000, Txt_img_0_0_loss: 0.49609 (0.49609) Txt_txt_0_1_loss: 0.16120 (0.16120) Weighted_mean_loss: 0.25882 (0.25882) Loss: 0.35305 (0.35305)\n",
            "2024-10-01,15:25:49 | INFO | Train Epoch: 1 [ 25856/100000 (26%)] Data (t): 0.000 Batch (t): 0.817, 313.793/s, 313.793/s/gpu LR: 0.000025 Logit Scale: 99.900, Logit Bias: 0.000, Txt_img_0_0_loss: 0.70964 (0.60286) Txt_txt_0_1_loss: 0.30825 (0.23472) Weighted_mean_loss: 0.39708 (0.32795) Loss: 0.53115 (0.44210)\n",
            "2024-10-01,15:27:11 | INFO | Train Epoch: 1 [ 51456/100000 (52%)] Data (t): 0.000 Batch (t): 0.816, 313.715/s, 313.715/s/gpu LR: 0.000030 Logit Scale: 99.839, Logit Bias: 0.000, Txt_img_0_0_loss: 0.73329 (0.64634) Txt_txt_0_1_loss: 0.21426 (0.22790) Weighted_mean_loss: 0.41174 (0.35588) Loss: 0.52315 (0.46911)\n",
            "2024-10-01,15:28:32 | INFO | Train Epoch: 1 [ 77056/100000 (77%)] Data (t): 0.000 Batch (t): 0.816, 313.586/s, 313.586/s/gpu LR: 0.000035 Logit Scale: 99.756, Logit Bias: 0.000, Txt_img_0_0_loss: 0.82487 (0.69097) Txt_txt_0_1_loss: 0.39978 (0.27087) Weighted_mean_loss: 0.49125 (0.38972) Loss: 0.63519 (0.51063)\n",
            "2024-10-01,15:29:45 | INFO | Train Epoch: 1 [ 99840/100000 (100%)] Data (t): 0.001 Batch (t): 0.816, 314.367/s, 314.367/s/gpu LR: 0.000039 Logit Scale: 99.672, Logit Bias: 0.000, Txt_img_0_0_loss: 0.80586 (0.71395) Txt_txt_0_1_loss: 0.38571 (0.29384) Weighted_mean_loss: 0.44872 (0.40152) Loss: 0.61154 (0.53081)\n",
            "METRIC: epochTime=320;\n",
            "Uploading {'logs/model/checkpoints/epoch_1.pt'} to model/a4f61808-819f-4576-8fd2-30144047a1d4, current file: logs/model/checkpoints/epoch_2.pt\n",
            "Uploading files\n",
            "Uploading files from local to bucket fb1v8ftn-bucket\n",
            "2024-10-01,15:29:47 | INFO | Start epoch 2\n",
            "2024-10-01,15:29:51 | INFO | Train Epoch: 2 [   256/100000 (0%)] Data (t): 2.910 Batch (t): 3.771, 67.8796/s, 67.8796/s/gpu LR: 0.000039 Logit Scale: 99.671, Logit Bias: 0.000, Txt_img_0_0_loss: 0.49554 (0.49554) Txt_txt_0_1_loss: 0.22666 (0.22666) Weighted_mean_loss: 0.23245 (0.23245) Loss: 0.36255 (0.36255)\n",
            "2024-10-01,15:31:13 | INFO | Train Epoch: 2 [ 25856/100000 (26%)] Data (t): 0.000 Batch (t): 0.818, 313.365/s, 313.365/s/gpu LR: 0.000044 Logit Scale: 99.630, Logit Bias: 0.000, Txt_img_0_0_loss: 0.53542 (0.51548) Txt_txt_0_1_loss: 0.21629 (0.22147) Weighted_mean_loss: 0.26655 (0.24950) Loss: 0.38842 (0.37548)\n",
            "2024-10-01,15:32:34 | INFO | Train Epoch: 2 [ 51456/100000 (52%)] Data (t): 0.000 Batch (t): 0.817, 313.405/s, 313.405/s/gpu LR: 0.000049 Logit Scale: 99.525, Logit Bias: 0.000, Txt_img_0_0_loss: 0.70212 (0.57769) Txt_txt_0_1_loss: 0.17545 (0.20613) Weighted_mean_loss: 0.34819 (0.28239) Loss: 0.48197 (0.41098)\n",
            "2024-10-01,15:33:56 | INFO | Train Epoch: 2 [ 77056/100000 (77%)] Data (t): 0.001 Batch (t): 0.817, 313.450/s, 313.450/s/gpu LR: 0.000054 Logit Scale: 99.403, Logit Bias: 0.000, Txt_img_0_0_loss: 1.0565 (0.69739) Txt_txt_0_1_loss: 0.15751 (0.19398) Weighted_mean_loss: 0.43029 (0.31937) Loss: 0.67519 (0.47703)\n",
            "2024-10-01,15:35:09 | INFO | Train Epoch: 2 [ 99840/100000 (100%)] Data (t): 0.001 Batch (t): 0.816, 314.101/s, 314.101/s/gpu LR: 0.000058 Logit Scale: 99.306, Logit Bias: 0.000, Txt_img_0_0_loss: 0.91020 (0.73995) Txt_txt_0_1_loss: 0.28714 (0.21261) Weighted_mean_loss: 0.45882 (0.34726) Loss: 0.64159 (0.50994)\n",
            "METRIC: epochTime=321;\n",
            "Uploading {'logs/model/checkpoints/epoch_2.pt'} to model/a4f61808-819f-4576-8fd2-30144047a1d4, current file: logs/model/checkpoints/epoch_3.pt\n",
            "Uploading files\n",
            "Uploading files from local to bucket fb1v8ftn-bucket\n",
            "2024-10-01,15:35:11 | INFO | Start epoch 3\n",
            "2024-10-01,15:35:15 | INFO | Train Epoch: 3 [   256/100000 (0%)] Data (t): 2.753 Batch (t): 3.648, 70.1745/s, 70.1745/s/gpu LR: 0.000059 Logit Scale: 99.303, Logit Bias: 0.000, Txt_img_0_0_loss: 0.51188 (0.51188) Txt_txt_0_1_loss: 0.18020 (0.18020) Weighted_mean_loss: 0.21393 (0.21393) Loss: 0.35447 (0.35447)\n",
            "2024-10-01,15:36:36 | INFO | Train Epoch: 3 [ 25856/100000 (26%)] Data (t): 0.001 Batch (t): 0.819, 313.345/s, 313.345/s/gpu LR: 0.000064 Logit Scale: 99.219, Logit Bias: 0.000, Txt_img_0_0_loss: 0.59166 (0.55177) Txt_txt_0_1_loss: 0.14171 (0.16095) Weighted_mean_loss: 0.22659 (0.22026) Loss: 0.38790 (0.37119)\n"
          ]
        }
      ],
      "source": [
        "model_name = f\"{training_data}-model-{suffix}\"\n",
        "print(f\"Training a new model ({model_name}):\")\n",
        "tuned_model = marqtune_client.train_model(\n",
        "    dataset_id=training_dataset.dataset_id,\n",
        "    model_name=f\"{training_data}-model-{suffix}\",\n",
        "    instance_type=InstanceType.BASIC,\n",
        "    base_model=f\"Marqo/{base_model}.{base_checkpoint}\",\n",
        "    hyperparameters=training_params,\n",
        "    wait_for_completion=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZKiIINTUteN"
      },
      "source": [
        "Note, the logs contain information about the training process. Here’s an example:\n",
        "\n",
        "```python\n",
        "1721298452795 2024-07-18 10:27:32,795 - INFO - 2024-07-18T10:27:22.521705828Z 2024-07-18,10:27:22 | INFO | Train Epoch: 0 [   256/100000 (0%)] Data (t): 1.996 Batch (t): 6.086, 42.0608/s, 42.0608/s/gpu LR: 0.000000 Logit Scale: 100.003, Logit Bias: 0.000, Txt_img_0_0_loss: 1.5323 (1.5323) Txt_txt_0_1_loss: 2.2189 (2.2189) Weighted_mean_loss: 1.1285 (1.1285) Loss: 1.6030 (1.6030)\n",
        "1721298602882 2024-07-18 10:30:02,882 - INFO - 2024-07-18T10:29:57.309371399Z 2024-07-18,10:29:57 | INFO | Train Epoch: 0 [ 25856/100000 (26%)] Data (t): 0.742 Batch (t): 1.548, 160.529/s, 160.529/s/gpu LR: 0.000005 Logit Scale: 99.984, Logit Bias: 0.000, Txt_img_0_0_loss: 0.89163 (1.2119) Txt_txt_0_1_loss: 0.40258 (1.3107) Weighted_mean_loss: 0.61996 (0.87425) Loss: 0.70145 (1.1522)\n",
        "1721298762976 2024-07-18 10:32:42,975 - INFO - 2024-07-18T10:32:34.148183677Z 2024-07-18,10:32:34 | INFO | Train Epoch: 0 [ 51456/100000 (52%)] Data (t): 0.766 Batch (t): 1.568, 161.327/s, 161.327/s/gpu LR: 0.000010 Logit Scale: 99.969, Logit Bias: 0.000, Txt_img_0_0_loss: 0.89120 (1.1050) Txt_txt_0_1_loss: 0.32536 (0.98227) Weighted_mean_loss: 0.66933 (0.80594) Loss: 0.69427 (0.99957)\n",
        "1721298913063 2024-07-18 10:35:13,063 - INFO - 2024-07-18T10:35:10.632618682Z 2024-07-18,10:35:10 | INFO | Train Epoch: 0 [ 77056/100000 (77%)] Data (t): 0.762 Batch (t): 1.565, 167.016/s, 167.016/s/gpu LR: 0.000015 Logit Scale: 99.943, Logit Bias: 0.000, Txt_img_0_0_loss: 1.0737 (1.0972) Txt_txt_0_1_loss: 0.36037 (0.82679) Weighted_mean_loss: 0.74134 (0.78979) Loss: 0.81226 (0.95274)\n",
        "1721299053145 2024-07-18 10:37:33,145 - INFO - 2024-07-18T10:37:29.910381986Z 2024-07-18,10:37:29 | INFO | Train Epoch: 0 [ 99840/100000 (100%)] Data (t): 0.762 Batch (t): 1.565, 165.425/s, 165.425/s/gpu LR: 0.000019 Logit Scale: 99.911, Logit Bias: 0.000, Txt_img_0_0_loss: 0.97796 (1.0733) Txt_txt_0_1_loss: 0.27951 (0.71734) Weighted_mean_loss: 0.60969 (0.75377) Loss: 0.71128 (0.90445)\n",
        "```\n",
        "\n",
        "We see here information about the epoch, data, batch, logit scale, logit bias, text-image loss, text-text loss, weighted mean loss and loss."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hY2f1_p5Vboa"
      },
      "source": [
        "### **5. Evaluation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_nHDCYqUy7b"
      },
      "source": [
        "Once we've successfully tuned the model we will want to be able to quantify the performance of the tuned model against the baseline set by the original base model. To do this we can get Marqtune to use the evaluation dataset to run a an evaluation on the original base model to establish a baseline and then a subsequent evaluation with the same dataset on the last checkpoint generated by our freshly tuned model.\n",
        "\n",
        "Finally, we will print out the results of each evaluation which should show the tuned model returning better performance numbers than the base model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-BKvi53YwRVa"
      },
      "outputs": [],
      "source": [
        "eval_params = {\n",
        "    \"leftKeys\": [\"query\"],\n",
        "    \"leftWeights\": [1],\n",
        "    \"rightKeys\": [\"image\", \"title\"],\n",
        "    \"rightWeights\": [0.9, 0.1],\n",
        "    \"weightKey\": \"score\",\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbaSePEQwU8I"
      },
      "outputs": [],
      "source": [
        "print(\"Evaluating the base model:\")\n",
        "base_model_eval = marqtune_client.evaluate(\n",
        "    dataset_id=eval_dataset.dataset_id,\n",
        "    model=f\"Marqo/{base_model}.{base_checkpoint}\",\n",
        "    hyperparameters=eval_params,\n",
        "    wait_for_completion=True,\n",
        ")\n",
        "\n",
        "print(\"Evaluating the tuned model:\")\n",
        "tuned_model_id = tuned_model.model_id\n",
        "tuned_checkpoint = tuned_model.describe()[\"checkpoints\"][-1]\n",
        "tuned_model_eval = marqtune_client.evaluate(\n",
        "    dataset_id=eval_dataset.dataset_id,\n",
        "    model=f\"{tuned_model_id}/{tuned_checkpoint}\",\n",
        "    hyperparameters=eval_params,\n",
        "    wait_for_completion=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WerYYEacwYwA"
      },
      "outputs": [],
      "source": [
        "# convenience function to inspect evaluation logs and extract the results\n",
        "def print_eval_results(description, evaluation):\n",
        "    results = next(\n",
        "        (\n",
        "            json.loads(log[\"message\"][index:].replace(\"'\", '\"'))\n",
        "            for log in evaluation.logs()[-10:]\n",
        "            if (index := log[\"message\"].find(\"{'mAP@1000': \")) != -1\n",
        "        ),\n",
        "        None,\n",
        "    )\n",
        "    print(description)\n",
        "    print(json.dumps(results, indent=4))\n",
        "\n",
        "\n",
        "print_eval_results(\"Evaluation results from base model:\", base_model_eval)\n",
        "print_eval_results(\"Evaluation results from tuned model:\", tuned_model_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XP5kAtaYU728"
      },
      "source": [
        "Again, we've chosen a minimal set of hyperparameters for the evaluation tasks, and you can read about these in the [Evaluation Parameters documentation](https://docs.marqo.ai/2.10/Marqtune/API/evaluation/evaluation_parameters/).\n",
        "\n",
        "Due to the inherent stochasticity of training and evaluation the results you see will likely be different from our measurements, but you should see improvements similar to the measurements below (higher numbers are better)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PgDOHEeCU-33"
      },
      "source": [
        "Picking out one of the above metrics: NDCG@10 (Normalized Discounted Cumulative Gain - a measure of the ranking and retrieval quality of the model by comparing top 10 model retrievals with the ground truth) we can see our tuned model performed better than the base model. Similarly, the other metrics also show consistent improvements. Refer to our blog post on [Generalised Contrastive Learning for Multimodal Retrieval and Ranking](https://www.marqo.ai/blog/generalized-contrastive-learning-for-multi-modal-retrieval-and-ranking) for more information as well as an explanation of each of the metrics above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79NAuN10VngO"
      },
      "source": [
        "### **6. Download and Cleanup**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iysh9bsfVuJN"
      },
      "source": [
        "At this point, you can download the model to your local disk:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBpZefDCSZGL"
      },
      "outputs": [],
      "source": [
        "tuned_model.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "brQaGrhrVwZJ"
      },
      "source": [
        "From here you can choose to [create a Marqo index with this custom model](https://gh-previews.marqo.pages.dev/marqtune_walkthrough/Guides/Models-Reference/bring_your_own_model/#3-use-your-model-in-marqo).\n",
        "\n",
        "Finally, you can choose to (optionally) clean up your generated resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZG_kYvTSUps"
      },
      "outputs": [],
      "source": [
        "training_dataset.delete()\n",
        "eval_dataset.delete()\n",
        "tuned_model.delete()\n",
        "base_model_eval.delete()\n",
        "tuned_model_eval.delete()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UEsoiCTV3ts"
      },
      "source": [
        "### **Conclusion**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hnm0T_V0V6kL"
      },
      "source": [
        "This notebook has guided you through the process of fine-tuning a base open clip model using a multi-modal training dataset with Marqtune. We evaluated the performance of this newly fine-tuned model and found significant improvements when compared to the base model. [Marqtune](https://cloud.marqo.ai/) can be used to fine-tune a variety of different models—try it yourself, today!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c63eGlW6WBky"
      },
      "source": [
        "### **Code**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQlT0elxWD-I"
      },
      "source": [
        "You can find this code on our GitHub [here](https://github.com/marqo-ai/marqtune-examples/)."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
